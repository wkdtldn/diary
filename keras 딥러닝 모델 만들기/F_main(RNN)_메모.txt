## 오류를 찾지 못함


line 1 . numpy import
    - numpy : 대규모 다차원 배열을 쉽게 처리할 수 있도록 하는 파이썬 라이브러리.
    - reuters datasets을 통해 얻은 데이터들을 관리하기 위해 사용됨.

line 3 . sklearn import
    - sklearn : 파이썬 프로그래밍 언어 자유 소프트웨어 기계 학습을 위한 라이브러리.
    - 딥러닝 모델을 만드는데 사용되는 라이브러리 중 하나(더 검색이 필요)

line 4 . keras 데이터셋 import
    - reuters : 통신사 기업 중 하나로 데이터 셋으로 이용하기 위해 불러옴

line 5, 6 . keras 에 포함된 것
    - 이 밖에 다른 것들 import

line 17 . reuters 데이터 저장
    - X_train, y_train = 학습시키기 위한 데이터
    - X_test, y_test = 학습된 모델을 수행시키기 위한 데이터
        => reuters 데이터셋을 저장 혹은 정렬

line 21, 26 . padding
    - 자연어 처리를 하다보면 각 문장은 서로 길이가 다를 수 O
    - 기계는 동일한 문서들에 대해 하나의 행렬을 보고 처리
        => 이러한 작업
    - post-padding = pre-padding 과 다르게 앞단이 아닌 뒷단에 0을 배치하여 성능에서는 pre-padding 보다 떨어진다.(더 검색이 필요)

line 33, 36 . np reshape
    - numpy 를 사용해 다른 형태의 자료들로 변환

line 43, 46 . y_data 정리
    - 43 : y_train 데이터와 y_test 데이터를 합친다
    - 46 : 합쳐진 y_data를 one-hot encoding 형태로 바꾼다
    - One-hot Encoding : 단어 집합(문장)의 크기를 벡타의 차원으로 하여 단어 하나하나의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 벡타 표현 방식
        ex) ['나', '는', '자연어', '처리', '를', '배운다'] => {'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5} => [0, 0, 1, 0, 0, 0]

